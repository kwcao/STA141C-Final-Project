{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINAL MODELS\n",
    "\n",
    "- codes only \n",
    "- report uses results from:\n",
    "    - GradientBoosting and Neural Network.ipynb\n",
    "    - Random Forest Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import ensemble, metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "\n",
    "df = pd.read_csv(\"cleanedData.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Random Forest Regression \n",
    "df.dtypes\n",
    "hours = pd.to_datetime(df['Time']).dt.hour\n",
    "hours.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loca  = df['Location Description']\n",
    "loca.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf = df.copy()\n",
    "\n",
    "# its hard to build a model that predicts the type of a crime location\n",
    "# in 157 categories, therefore, we separate these location types into fewer categories \n",
    "# 1. Residential Area, 2.Public Open Space, 3. Non-Resid Buildings 4. Transporatation, 0.OTHER\n",
    "newDf.loc[:, 'Loca Num'] = np.where( loca.str.contains('RESIDEN')\n",
    "                                    |loca.str.contains('APARTMENT'), 1,\n",
    "                                    np.where(loca.str.contains('STREET')\n",
    "                                             |loca.str.contains('SIDEWALK')\n",
    "                                             |loca.str.contains('STATION')\n",
    "                                             |loca.str.contains('LOT')\n",
    "                                             |loca.str.contains('ALLEY')\n",
    "                                             |loca.str.contains('PLATFORM')\n",
    "                                             |loca.str.contains('HIGHWAY')\n",
    "                                             |loca.str.contains('BRIDGE')\n",
    "                                             |loca.str.contains('LAKEFRONT')\n",
    "                                             |loca.str.contains('FOREST')\n",
    "                                             |loca.str.contains('LAKE')\n",
    "                                             |loca.str.contains('RIVER')\n",
    "                                             |loca.str.contains('PARK'), 2,\n",
    "                                             np.where(loca.str.contains('BUILDING')\n",
    "                                                      |loca.str.contains('STORE')\n",
    "                                                      |loca.str.contains('RESTAURANT')\n",
    "                                                      |loca.str.contains('SCHOOL')\n",
    "                                                      |loca.str.contains('OFFICE')\n",
    "                                                      |loca.str.contains('HOTEL')\n",
    "                                                      |loca.str.contains('BANK')\n",
    "                                                      |loca.str.contains('CONSTRUCTION SITE')\n",
    "                                                      |loca.str.contains('CLUB')\n",
    "                                                      |loca.str.contains('BARBERSHOP')\n",
    "                                                      |loca.str.contains('COLLEGE')\n",
    "                                                      |loca.str.contains('LIBRARY')\n",
    "                                                      |loca.str.contains('ATM')\n",
    "                                                      |loca.str.contains('CENTER')\n",
    "                                                      |loca.str.contains('THEATER')\n",
    "                                                      |loca.str.contains('CHURCH')\n",
    "                                                      |loca.str.contains('STADIUM')\n",
    "                                                      |loca.str.contains('FACILITY')\n",
    "                                                      |loca.str.contains('SHOP')\n",
    "                                                      |loca.str.contains('HOSPITAL')\n",
    "                                                      |loca.str.contains('CREDIT UNION')\n",
    "                                                      |loca.str.contains('MOTEL')\n",
    "                                                      |loca.str.contains('AIRPORT')\n",
    "                                                      |loca.str.contains('FACTORY')\n",
    "                                                      |loca.str.contains('ROOM')\n",
    "                                                      |loca.str.contains('BAR'), 3,\n",
    "                                                      np.where( loca.str.contains('TRANSPORTATION')\n",
    "                                                                |loca.str.contains('TRUCK')\n",
    "                                                                |loca.str.contains('BUS')\n",
    "                                                                |loca.str.contains('TAXICAB')\n",
    "                                                                |loca.str.contains('VEHICLE')\n",
    "                                                                |loca.str.contains('TRAIN'), 4,\n",
    "                                                                0))))\n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding categorical data \n",
    "newDf.drop(['ID', 'Time', 'Location Description'], axis = 1, inplace = True)\n",
    "newDf['Hours'] = hours\n",
    "\n",
    "# all categorical data\n",
    "categories = ['IUCR','Arrest',\n",
    "           'FBI Code', 'Domestic', 'Month', 'DayofWeek',\n",
    "           'PRIMARY DESCRIPTION', 'SECONDARY DESCRIPTION', 'INDEX CODE', 'Hours']\n",
    "encoders = {}\n",
    "\n",
    "for i in categories:\n",
    "    # Create a label (category) encoder object\n",
    "    encoders[i] = preprocessing.LabelEncoder()\n",
    "\n",
    "    # Fit the encoder to the pandas column\n",
    "    encoders[i].fit(newDf[i])\n",
    "    \n",
    "    # View the labels (if you want)\n",
    "    #list(le.classes_)\n",
    "    \n",
    "    # Apply the fitted encoder to the pandas column\n",
    "    trans = encoders[i].transform(newDf[i]) \n",
    "    \n",
    "    # Append to DataFrame\n",
    "    newName = i + '_encoded'\n",
    "    newDf.loc[:, newName] = pd.Series(trans, index = newDf.index)\n",
    "\n",
    "newDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_map(df):\n",
    "    \"\"\"\n",
    "    This function plots the correlation map of a given dataframe\n",
    "    \"\"\"\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =(24, 20 ) )\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n",
    "\n",
    "\n",
    "plot_correlation_map(newDf)\n",
    "newDf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FEATURES: TIME, LOCATION, determine TYPE \n",
    "location = newDf['Location Description_encoded']\n",
    "train1 = newDf[['Month_encoded', 'DayofWeek_encoded',\n",
    "           'PRIMARY DESCRIPTION_encoded', 'Hours', 'District']]\n",
    "\n",
    "\n",
    "# split our data into train and test\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , location , test_size = 0.30,random_state =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build random forest model\n",
    "\n",
    "# count time building the model \n",
    "time_start = time.clock()\n",
    "\n",
    "trees = 35\n",
    "depth = 15\n",
    "\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=trees, max_depth=depth)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "pred = rf.predict(x_test)\n",
    "comparison = pd.crosstab(y_test, pred)\n",
    "\n",
    "time1 = (time.clock() - time_start)\n",
    "print(\"time to build a Random Forest Model is:\", time1)\n",
    "print(\"mean accuracy on the given test data and labels is:\", rf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays the precision, recall, F1, and support scores for the model\n",
    "\n",
    "# Precision is the ability of a classiifer not to label an instance positive that is actually negative. \n",
    "# for all instances classified positive, what percent was correct\n",
    "\n",
    "# Recall is the ability of a classifier to find all positive instances.\n",
    "# for all instances that were actually positive, what percent was classified correctly\n",
    "\n",
    "# The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0\n",
    "\n",
    "# Support is the number of actual occurrences of the class in the specified dataset. \n",
    "\n",
    "report =  metrics.classification_report(y_test, pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "# https://towardsdatascience.com/demystifying-confusion-matrix-confusion-9e82201592fd\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=3)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=newDf['Location Description_encoded'].unique().tolist(),\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[1,2,3], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting \n",
    "# so a large number usually results in better performance.\n",
    "\n",
    "# count time building the model \n",
    "time_start = time.clock()\n",
    "\n",
    "gbr3 = ensemble.GradientBoostingRegressor(n_estimators = 50, max_depth = 5,\n",
    "                                         loss = 'ls')\n",
    "\n",
    "gbr3.fit(x_train, y_train)\n",
    "\n",
    "gbr_pred3 = gbr3.predict(x_test)\n",
    "gbr_comparison3 = pd.crosstab(y_test, gbr_pred3)\n",
    "\n",
    "grd_time3 = (time.clock() - time_start)\n",
    "print(\"time to build a Gradient Boosting Model is:\", grd_time3)\n",
    "print(\"Test Accuracy: \", metrics.accuracy_score(y_test, gbr_pred3.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report =  metrics.classification_report(y_test, gbr_pred3.round())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, gbr_pred3.round())\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[1,2,3,4],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.savefig('gbr_cm_wo_normal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[1,2,3,4], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('gbr_cm_w_normal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = to_categorical(y_train, num_classes=5)\n",
    "y_test2 = to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/deep-learning-for-beginners-practical-guide-with-python-and-keras-d295bfca4487\n",
    "\n",
    "# count time building the model \n",
    "time_start = time.clock()\n",
    "\n",
    "nn2 = Sequential()\n",
    "nn2.add(Dense(128, input_dim=5, activation='relu'))\n",
    "nn2.add(Dense(128, activation='relu'))\n",
    "nn2.add(Dense(128, activation='relu'))\n",
    "nn2.add(Dense(128, activation='relu'))\n",
    "nn2.add(Dense(5, activation='softmax'))\n",
    "nn2.compile(loss='categorical_crossentropy',optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "nn2.fit(x_train, y_train2, batch_size=128, epochs=5)\n",
    "nn_pred2 = nn2.predict_classes(x_test)\n",
    "\n",
    "nn_time2 = (time.clock() - time_start)\n",
    "print(\"time to build a Neural Network Model is:\", nn_time2)\n",
    "print(\"Test Accuracy: \", metrics.accuracy_score(y_test, nn_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report =  metrics.classification_report(y_test, nn_pred2)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, nn_pred2)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[1,2,3,4],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.savefig('nn_cm_wo_normal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[1,2,3,4], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('nn_cm_w_normal.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
